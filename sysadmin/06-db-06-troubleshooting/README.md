# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
> Сначала необходимо определить запрос, выполняющийся более 3 минут: 
> ``` 
> use <YOUR-DB>;
> db.currentOp().inprog.forEach(
>   function(d){
>     if(d.secs_running > 180)
>        printjson(d)
> })
> ```
> Завершить запрос: 
> ```
> db.killOp(<opid>)
> ```
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB
> Можно установить ограничение на время исполнения запроса добавив maxTimeMS, например: 
> ```
> db.runCommand( { distinct: "collection",
>                 key: "city",
>                 maxTimeMS: 45 } ) 
> ```
 

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

> Redis раз в 100 мс запускает задачу по очистке истекших(просроченных) значений (и очищает (по умолчанию) 200 просроченных key-value значений за цикл).
> Если количество просроченных значений в базе более 25% - процедура запускается вновь до снижения показателя менее 25% в инстансе.
> 
> Проблема может быть в том, что % истекших key-value значений превышает порог в 25% и Redis блокирует операции записи на время работы "очистки" инстанса от просроченных пар значений до значения менее 25%. 


 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

> Даная ошибка может возникать по ряду причин:
> 
> В случае отправки большого количества строк (миллионы) отправляются в одном или нескольких запросах на сервер. Исправить можно увеличив параметр net_read_timeout с 30 секунд (по-дефолту) до, например, 60 секунд или более (время, достаточное, для передачи данных). 
> 
> С меньшей долей вероятности данная ошибка может проявляться, когда клиент инициализирует соединение с сервером, но из-за плохой связи или очень большого расстояния сервер сбрасывает соединение в связи с низким значением connection_timeout (пару секунд по-умолчанию). 
> Определить данную ошибку можно введя запрос:  `SHOW GLOBAL STATUS LIKE 'Aborted_connects'`. Данный счетчик увеличивается с каждым "сброшенным" соединением. 
> Если данные счетчика растут - ошибка локализована. Так же в теле ошибки можно увидеть упоминание `reading authorization packet` - тоже маркер низкого значения connection_timeout. 
> 
> **Наиболее вероятная причина ошибки, на мой взгляд.** Если предыдущие два варианта не подошли - вероятна ошибка с BLOB значениями, большими, чем определено в параметре сервера `max_allowed_packet`. 
> В данном случае необходимо в логах искать иногда возникающую ошибку `ER_NET_PACKET_TOO_LARGE` - если ошибка появляется - проблема локализована. Для исправления необходимо увеличить значение параметра `max_allowed_packet`.
 



## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?
> oom-killer -  расшифровывается как "out of memory killer" - процесс, завершающий процесс в случае нехватки ресурсов (памяти), для предотвращения сбоя ядра ОС. 
> 
>Процесс postgres начинает потреблять очень много памяти, и когда она заканчивается oom-killer завершает процесс для "спасения" ОС. 

Как бы вы решили данную проблему?

 
> Настройка PostrgeSQL, чтобы не "съедал" всю память.
> 
> Наиболее важные параметры: **max_connections, shared_buffer, work_mem, effective_cache_size, maintenance_work_mem.**
> 
> max_connections - Определяет максимальное число одновременных подключений к серверу БД. По умолчанию обычно это 100 подключений, но это число может быть меньше, если ядро накладывает свои ограничения (это определяется в процессе initdb). Этот параметр можно задать только при запуске сервера.
> 
>shared_buffers - Объем выделенной памяти для кэширования.
> 
>wal_buffers - Объем журнала записи PostgreSQL (сначала операции записываются в WAL, потом на диск.) По умолчанию 16 Мб. Если большое количество подключений -более высокое значение может повысть производительность БД.
> 
>Work_mem - объем памяти для выполнения сортировок.
> 
>effective_cache_size - Определяет представление планировщика об эффективном размере дискового кеша, доступном для одного запроса. Это представление влияет на оценку стоимости использования индекса; чем выше это значение, тем больше вероятность, что будет применяться сканирование по индексу, чем ниже, тем более вероятно, что будет выбрано последовательное сканирование. Кроме того, следует принять во внимание ожидаемое число параллельных запросов к разным таблицам, так как общий размер будет разделяться между ними. Этот параметр не влияет на размер разделяемой памяти, выделяемой &project;, и не задаёт размер резервируемого в ядре дискового кеша; он используется только в качестве ориентировочной оценки. При этом система не учитывает, что данные могут оставаться в дисковом кеше от запроса к запросу. Значение этого параметра по умолчанию — 4 гигабайта (4GB).
> 
>maintenance_work_mem - Задаёт максимальный объём памяти для операций обслуживания БД, в частности VACUUM, CREATE INDEX и ALTER TABLE ADD FOREIGN KEY. По умолчанию его значение — 64 мегабайта (64MB). Так как в один момент времени в сеансе может выполняться только одна такая операция, и обычно они не запускаются параллельно, это значение вполне может быть гораздо больше work_mem. Увеличение этого значения может привести к ускорению операций очистки и восстановления БД из копии.
> 


