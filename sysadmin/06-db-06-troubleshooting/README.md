# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
> Сначала необходимо определить запрос, выполняющийся более 3 минут: 
> ``` 
> use <YOUR-DB>;
> db.currentOp().inprog.forEach(
>   function(d){
>     if(d.secs_running > 180)
>        printjson(d)
> })
> ```
> Завершить запрос: 
> ```
> db.killOp(<opid>)
> ```
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB
> Можно установить ограничение на время исполнения запроса добавив maxTimeMS, например: 
> ```
> db.runCommand( { distinct: "collection",
>                 key: "city",
>                 maxTimeMS: 45 } ) 
> ```
 

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

> Redis раз в 100 мс запускает задачу по очистке истекших(просроченных) значений (и очищает (по умолчанию) 200 просроченных key-value значений за цикл).
> Если количество просроченных значений в базе более 25% - процедура запускается вновь до снижения показателя менее 25% в инстансе.
> 
> Проблема может быть в том, что % истекших key-value значений превышает порог в 25% и Redis блокирует операции записи на время работы "очистки" инстанса от просроченных пар значений до значения менее 25%. 


 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

> Даная ошибка может возникать по ряду причин:
> 
> В случае отправки большого количества строк (миллионы) отправляются в одном или нескольких запросах на сервер. Исправить можно увеличив параметр net_read_timeout с 30 секунд (по-дефолту) до, например, 60 секунд или более (время, достаточное, для передачи данных). 
> 
> С меньшей долей вероятности данная ошибка может проявляться, когда клиент инициализирует соединение с сервером, но из-за плохой связи или очень большого расстояния сервер сбрасывает соединение в связи с низким значением connection_timeout (пару секунд по-умолчанию). 
> Определить данную ошибку можно введя запрос:  `SHOW GLOBAL STATUS LIKE 'Aborted_connects'`. Данный счетчик увеличивается с каждым "сброшенным" соединением. 
> Если данные счетчика растут - ошибка локализована. Так же в теле ошибки можно увидеть упоминание `reading authorization packet` - тоже маркер низкого значения connection_timeout. 
> 
> **Наиболее вероятная причина ошибки, на мой взгляд.** Если предыдущие два варианта не подошли - вероятна ошибка с BLOB значениями, большими, чем определено в параметре сервера `max_allowed_packet`. 
> В данном случае необходимо в логах искать иногда возникающую ошибку `ER_NET_PACKET_TOO_LARGE` - если ошибка появляется - проблема локализована. Для исправления необходимо увеличить значение параметра `max_allowed_packet`.
 



## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?
> oom-killer -  расшифровывается как "out of memory killer" - процесс, завершающий процесс в случае нехватки ресурсов (памяти), для предотвращения сбоя ядра ОС. 
> 
>Процесс postgres начинает потреблять очень много памяти, и когда она заканчивается oom-killer завершает процесс для "спасения" ОС. 

Как бы вы решили данную проблему?

> Либо увеличение доступной памяти на сервере.
> 
> Либо настройка PostrgeSQL, чтобы не "съедал" всю память.
> 
> Либо настройка oom-killer'a, (vm.overcommit_memory = 2 - ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio.)
> 
> Отключать oom-killer не рекомендуется, хотя тоже возможно. 
> 


